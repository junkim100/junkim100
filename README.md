### Hi there, I'm [Dong Jun Kim](https://junkim100.github.io) ðŸ‘‹

I'm currently pursuing my Ph.D. at at [Korea University](https://www.korea.edu)'s [NLP&AI Lab](http://nlp.korea.ac.kr), specializing in **Mechanistic Interpretability of Large Language Models (LLMs)**. My research focuses on understanding the internal workings of LLMs, developing methods to make their decision-making processes more transparent and interpretable. I am passionate about advancing the field of AI by improving our ability to analyze and explain model behavior at a granular level.

**Research Interests**:
- Mechanistic Interpretability of LLMs
- Sparse Autoencoders & LLM Circuits
- Retrieval-Augmented Generation (RAG)
- LLM Architectures & Optimization
- Efficient Fine-tuning Techniques

**Open to**:
- Research collaborations in AI/ML
- Industry partnerships for LLM development
- Reviewer or PC member roles for AI/ML conferences or journals

## Skills

#### Core Expertise:

- **Mechanistic Interpretability**: Developing novel techniques to understand the internal structures and decision-making pathways in LLMs.
- **Sparse Autoencoders & LLM Circuits**: Researching sparse representations and circuit-level analysis within LLMs to enhance interpretability.
- **LLM Architectures**: Designing and optimizing large-scale architectures for efficiency and performance.
- **Retrieval-Augmented Generation (RAG)**: Integrating retrieval mechanisms with generative models to improve accuracy and relevance in language generation tasks.

#### Machine Learning & Deep Learning Frameworks:

![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)&nbsp;
![DeepSpeed](https://img.shields.io/badge/DeepSpeed-FF6F00?style=for-the-badge&logoColor=white)&nbsp;
![Flax](https://img.shields.io/badge/Flax-%23007ACC.svg?style=for-the-badge&logoColor=white)&nbsp;
![Hugging Face](https://img.shields.io/badge/Hugging%20Face-%23FF9900.svg?style=for-the-badge&logo=huggingface&logoColor=white)&nbsp;
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)&nbsp;

#### Tools & Technologies:

![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)&nbsp;
![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)&nbsp;
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)&nbsp;
![Weights & Biases](https://img.shields.io/badge/W%26B-%23FFBE00.svg?style=for-the-badge&logo=w%26b&logoColor=black)
![CodaLab](https://img.shields.io/badge/CodaLab-%23000000.svg?style=for-the-badge&logo=codalab)
![bitsandbytes](https://img.shields.io/badge/BitsAndBytes-%23000000.svg?style=for-the-badge)

#### Optimization & Acceleration:

![ONNX Runtime](https://img.shields.io/badge/ONNX%20Runtime-%2320B2AA.svg?style=for-the-badge)
![TensorRT Optimization](https://img.shields.io/badge/TensorRT-%2300ADEF.svg?style=for-the-badge)

## Connect with me:

<p align="center">

[<img src="https://img.shields.io/badge/website-%23.svg?&style=for-the-badge&logo=www&logoColor=white%22&color=black" />]([https://github.com/junkim100](https://junkim100.github.io))
[<img src="https://img.shields.io/badge/LinkedIn-%2312100E.svg?style=for-the-badge&logo=linkedin&color=black" />](https://linkedin.com/in/junkim100/)
[<img src="https://img.shields.io/badge/Google%20Scholar-%2312100E.svg?style=for-the-badge&color=black" />](https://scholar.google.com/citations?user=ZE8__uoAAAAJ)
</p>

| <a href="https://github.com/anuraghazra/github-readme-stats"><img align="center" src="https://github-readme-stats.vercel.app/api?username=junkim100&show_icons=true&include_all_commits=true&theme=buefy&hide_border=true" alt="Dong Jun's github stats" /></a> | <a href="https://github.com/anuraghazra/github-readme-stats"><img align="center" src="https://github-readme-stats.vercel.app/api/top-langs/?username=junkim100&layout=compact&theme=buefy&hide_border=true" /></
